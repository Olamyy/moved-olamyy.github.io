{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender Systems filter items based on user-item (collaborative filtering ) patterns or item-content (content filtering) patterns. \n",
    "Collaborative filtering builds a model from a user's past patterns. It uses items previously purchased or selected and ratings (usually numerical) given by users of these items to make recommendations.\n",
    "Content filtering on the other hand uses the features of an item to recommend similar items to users.\n",
    "The focus of this article will be on a variant of collaborative filtering called `Deep Matrix Factorization`\n",
    "\n",
    "\n",
    "Collaboritive filtering systems require a large amount of data about users in order to make good recommendations. This often leads to 3 problems; Cold Start, Scalability and Sparsity.\n",
    "\n",
    "1. Cold Start<sup>1</sup> analogous to not having enough data about a user to make good recommendations.\n",
    "2. Scalabiltiy<sup>2</sup> in respect to the amount of compute needed to build an end-to-end recsys.\n",
    "3. Sparsity as a reference to the number of items that were successfully rated by users (Usually always really low).\n",
    "\n",
    "\n",
    "To solve the problem of sparsity, earlier systems relied on filling the missing rating (i.e making the data dense) with the average ratings for each user and item. This was expensive as it increases the amount of data significantly and introduces a lot of noise into the data. Simon Funk <sup>3</sup> while taking part in the Netflix Prize<sup>4</sup> proposed the Matrix Factorization idea for solving this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UserItemRating](/images/user_item.png)\n",
    "\n",
    "The collection of user, item, rating in a typical RecSys problem can be stored as a `sparse matrix` where users are in `rows` and items are in `columns` with the ratings as values in the matrix. The missing values in the matrix are unobserved instances i.e ratings to predict. and is essentially the task here. The prediction of these ratings  is usually done in one of 3 ways:\n",
    "\n",
    "1. If the data is numeric and bimodal between two distant values, the mean imputation is used to fill the data with values that otherwise would not exist in the dataset at all.\n",
    "2. If there are not many missing values then the mean or median value of the observed values is used to fill in the missing values.\n",
    "3. If the data is categorical, the most frequently observed value is used to fill in the missing values.\n",
    "\n",
    "The methods above have various challenges ranging from the introduction of noise into the dataset, to overlooking important iteractions between users and items.\n",
    "\n",
    "Matrix factorization is a solution to this problem that attempts to bypass the challenges above. It assumes that a bunch of hidden feature exists that determine how a user rates an item. For example, Users A and C could give high ratings to a particular Item B if they both like a certain thing about this item. As such, if we can discover what the hidden thing they both like about the item is, we should be able to predict a rating with respect to this user and other items.\n",
    "Assuming our sparse user-item-rating matrix is denoted by $A$, matrix factorization tries to learn a number of features, say $k$ that represents a user or item. Using the concept of matrix decomposition, $A$ is then decomposed into the dot product of two lower rank matrices $L$ and $U$, such that\n",
    "        $$A = L.U$$ where\n",
    "        \n",
    "          A = Our sparse matrix\n",
    "          L = user-factor matrix i.e features that stand out about the users \n",
    "          U = item-factor matrix i.e features that stand out about the items.                    \n",
    "The predicted rating for each missing value is then given as the sum of $k$ instances of the $L$ and $U$ reprisented as:\n",
    "                \n",
    "$$rating_{i,j} = \\sum_{l=1}^k \\ L_{i,l} . \\ U_{j,l} = U_{i,l}^T.L_{j,l}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the matrices $L$ and $U$, we need to go back to our matrix $A$.\n",
    "If $A$ is dense, i.e most of the elements are non-zero, the $L$ is the eigenvectors of $AA^T$ and U, the eigenvectos of $A^TA$. If $A$ is sparse, i.e most of the elements are zero, we can compute $L$ and $U$ using gradient descent. To do this, we set $L$ and $U$ to some initial random values, pick a random instance $B$ and then iteratively find the difference between $B$ and the product of $L$ and $U$. This iteration goes on till we reach a local minimal of the difference. The difference can be calculated using:\n",
    "    $$d_{i,j}^{2} = \\left(d_{i,j} - \\overbrace{d_{i,j}}\\right)^2$$\n",
    "    where $d_{i,j}$ = real rating and $\\overbrace{d_{i,j}}$ = predicted rating\n",
    "     \n",
    "Substituting our initial equation into this, we get:\n",
    "        $$\\left(d_{i,j} - \\overbrace{d_{i,j}}\\right)^2 = \\left(d_{i,j} - \\sum_{l=1}^k \\ L_{i,l} . \\ U_{j,l}\\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce $\\left(d_{i,j} - \\overbrace{d_{i,j}}\\right)^2$, i.e the error term, we need to update the values of $L_{i,l}$ and  $U_{j,l}$ at each level. To do this, we differentiate the equation above with respect to both $L_{i,l}$ and  $U_{j,l}$. This gives us:\n",
    "    $$\\frac{\\partial d_{i,l}^{2}}{\\partial L_{i,l}} = - 2d_{i,j}U_{l,j}$$ and $$\\frac{\\partial d_{i,l}^{2}}{\\partial U_{i,l}} = - 2d_{i,j}L_{i,l} $$\n",
    "    \n",
    "At this point, we can ascertain that $L_{i,l}$ can be updated with:\n",
    "    $$L^{'}_{il} \\ =L_{il} + 2\\alpha d_{ij} U_{lj} \\ $$\n",
    "\n",
    "Similarly, $U_{i,l}$ can be updated at each point with:\n",
    "    $$U^{'}_{lj} \\ =U_{il} + 2\\alpha d_{ij} L_{il} \\ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in every intelligent system, there's a need to consider the availability of `biases` in how users rate items. Biases are personal, important and often have a lasting effect in how users behave. Some users can rate items higher or lower in respect to their bias to these items. As a result of this, in making predictions for ratings, it is important we include some form of bias in our equation above. $\\overbrace{d_{i,j}}$ above with bias included becomes:\n",
    "        $$\\overbrace{d_{i,j}} = b_{user, i} + b_{item, j} + rating_{i,j}$$ where $b$ is the global bias, $b_{user, i}$ is the bias of a user $i$ and $b_{item, j}$ the bias of an item $j$.\n",
    "\n",
    "Since the entire matrix factorization idea is an gradient optimizing process, there will be a need to update the biases at each point of descent. We can achieve this by updating our biases at each point with:\n",
    "    $$b'_{user, i} = b_{user, i} + \\alpha \\times (d_{ij} - \\beta bu_i)$$\n",
    "       $$b'_{item, i} = b_{item, i} + \\alpha \\times (d_{ij} - \\beta bu_i)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To better illustrate matrix factorization, let's try a simple python implementation of the algorithm using a top down approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1 : Create the user-items-rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Simple matrix with ratings as element.\n",
    "### We're to predict the 0 values which are items that have not been rated yet.\n",
    "\n",
    "import numpy\n",
    "user_item_rating = numpy.array([[5, 3, 0, 1],\n",
    "                                [4, 0, 0, 1],\n",
    "                                [1, 1, 0, 5],\n",
    "                                [1, 0, 0, 4],\n",
    "                                [0, 1, 5, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2 : Find the values of L and U using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_l_u_gradient_descent(user_item_rating):\n",
    "    features = 2  # number of hidden factors in our matrix\n",
    "    alpha = 0.0002  # learning rate i.e $\\alpha$\n",
    "    beta = 0.02     # Bias\n",
    "    n_epochs = 1000  # number of iterations to run this for\n",
    "    \n",
    "    users, items = user_item_rating.shape  ### User and item features\n",
    "    \n",
    "    # Randomly initialize users and items\n",
    "    L = numpy.random.rand(users, features)\n",
    "    U = numpy.random.rand(items, features)\n",
    "    U = U.T\n",
    "    \n",
    "    samples = [\n",
    "            (i, j)\n",
    "            for i in range(users)\n",
    "            for j in range(items)\n",
    "            if user_item_rating[i][j] > 0\n",
    "        ] ### Map of items with no ratings. i.e ratings we're predicting for \n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        for i, j in samples:\n",
    "            d_ij = user_item_rating[i][j] - numpy.dot(L[i,:], U[:,j])     ### Get error term at each point of descent\n",
    "            for l in range(features):\n",
    "                L[i][l] = L[i][l] + alpha * (2 * d_ij * U[l][j] - beta * L[i][l]) ### Update L at each feature descent point.\n",
    "                U[l][j] = U[l][j] + alpha * (2 * d_ij * L[i][l] - beta * U[l][j]) ### Update U at each new feature descent point\n",
    "    return L, U.T   ### Return L and U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3 : Find the dot product of L and U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dot_l_u(l, u):\n",
    "    return numpy.dot(l, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this all together, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58193084, 2.11016737, 2.5515962 , 2.51643076],\n",
       "       [2.67882287, 1.53323706, 2.05104122, 2.06722282],\n",
       "       [2.77042234, 1.34618847, 2.88273825, 3.126065  ],\n",
       "       [2.03771395, 0.83453415, 2.61521841, 2.94143927],\n",
       "       [3.41638943, 1.50125544, 4.05995427, 4.51028962]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, U = find_l_u_gradient_descent(user_item_rating)\n",
    "\n",
    "find_dot_l_u(L, U.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A less hacky (and easily more practical) way of computing Matrix Factorization is to use the `SVD` (Singular Value Decomposition) module available in the `surprise` RecSys python package. It should however be noted that SVD is used mostly for dense matrices. It (SVD) makes it easy for the eigenvectors of these matrices to be calculated. The `NMF` ( Non-negative Matrix Factorization) module produces better predictions for sparse matrices since the missing values are included in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An often interesting challenge with RecSys is effectively handling the changing nature of both users and items. This time-drifting nature of data in RecSys, often goes a long way to determining the rating of items, since each new (time-based) selection leads to a change in user taste. Given this, a good RecSys should account for temporal changes in user tastes. Examples of timeseries plots (using the movielens data) showing this changing nature is shown below.\n",
    "\n",
    "![UserItemRating](/images/ts.png)\n",
    "*Image Source: [Github](https://github.com/WJMatthew/MovieLens-EDA) License MIT\n",
    "\n",
    "![UserItemRating](/images/ts_1.png)\n",
    "*Image Source: [Github](https://github.com/WJMatthew/MovieLens-EDA) License MIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items appear to have a very slow change with time. Users on the other hand exhibit frequent, sometimes sudden changes in their interest over time. This reinstates why bias is important in making predictions relating to users. The effect of bias on users can at this point be understood to be more important than that of items. The change is often in two forms.\n",
    "\n",
    "1. Multiple sources : Both items and users change with time.\n",
    "2. Multiple targets : Each user/item forms a unique map and change with time.\n",
    "\n",
    "To account for this change, we can introduce a time based constant, $t$ into our initial equation:\n",
    "    $$\\overbrace{d_{i,j}}(t) = b_{user, i}(t) + b_{item, j}(t) + rating_{i,j}(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since matrix factorization is essentially a linear representation of a matrix (dot product), a new challenge ensues when the matrix contains a lot of non-linear interactions. The success of deep learning in solving complicated machine learning (especially in computer vision and language processing) tasks in mostly non-linear spaces made it a natural solution to solving the non-linearity problem.\n",
    "\n",
    "There have been a number of implementations of matrix factorization using deep learning.  Restricted Boltzmann Machines [Salakhutdinov\n",
    "et al., 2007] was firstly proposed to model users’ explicit\n",
    "ratings on items. Autoencoders and the denoising autoencoders\n",
    "have also been applied for recommendation [Li et\n",
    "al., 2015; Sedhain et al., 2015; Strub and Mary, 2015]. The\n",
    "key idea of these methods is to reconstruct the users’ ratings\n",
    "through learning hidden structures with the explicit historical\n",
    "ratings. Implicit feedback is also applied in this research line\n",
    "of deep learning for recommendation.  [He et\n",
    "al., 2017] also attempted to model the user-item interactions\n",
    "with a multi-layer feedforward neural network. Regardless of the implementation chosen, the architecture is pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the user-item-rating matrix is represented as $A$, we can set up a simple architecture where users and items are represented as high-dimensional vectors of $A$. i.e $A_{*i}$ represents the $i_{th}$ user and $A_{*j}$ represents the $j_{th}$ item. In each layer of our architecture, we can map the input vectors into another vector in a new space configuration. If we denote the input and output vectors as $x$ and $y$ respectively, the hidden layers, say, $l_{i},i$ can be represented as :\n",
    "            $$l_{i}, i = 1, ..., N - 1 $$ where N is the number of layers.\n",
    "  This suggests that our first hidden layer will be:\n",
    "            $$l_{1} = W_{1}x$$\n",
    "   Finally, our hidden features can be computed as a function of the product of the weights $W_{N}$ and hidden layers $l_{N}$, i.e\n",
    "   $$h = f(W_{n}l_{n-1} + b_{N})$$ where $h$ is the hidden feature and $b$ bias. \n",
    "\n",
    "Following this pattern, our final architecture ends up to containing two multi-layer networks mapped to hidden layers of low-dimensional vector as shown below. A ReLU activation can be applied at each point of the network and the similarity between hidden features calculated using cosine similarity.\n",
    "\n",
    "![DMF Architecture](/images/dmf_layers.png)\n",
    "\n",
    "Deep matrix factorization provides a leverage over the normal matrix factorization in that output size of the embedded layer is not restricted to a particular value. This is useful in the case where one dimension may be significantly larger than the other and thus requires training a massive number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of the DMF using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Reshape, Dense, dot\n",
    "from keras.models import Sequential\n",
    "\n",
    "class DMF(Sequential):\n",
    "    def __init__(self, data, features= 2 , alpha= 0.0002, beta = 0.02 , n_epochs= 1000, **kwargs):\n",
    "        self.features = features  # number of hidden factors in our matrix\n",
    "        self.alpha = alpha  # learning rate i.e $\\alpha$\n",
    "        self.beta = beta    # Bias\n",
    "        self.n_epochs = n_epochs  # number of iterations to run this for\n",
    "        self.l_count = 5\n",
    "        self.data = data\n",
    "        self.users, self.items = self.data.shape  ### User and item features\n",
    "        \n",
    "        self.setup_L()\n",
    "        self.setup_U()\n",
    "        \n",
    "        super(DMF, self).__init__(**kwargs)\n",
    "        \n",
    "        self.add(dot([L, U], axes=1, normalize=False))\n",
    "        \n",
    "        \n",
    "    def setup_L(self):\n",
    "        L = Sequential()\n",
    "        for i in range(self.l_count):\n",
    "            L.add(Dense(data.shape[0], activation='relu'))\n",
    "        l_embedding = Embedding(users, features, input_length=1)\n",
    "        L.add(l_embedding)\n",
    "        L.add(Reshape((features,)))\n",
    "        return L\n",
    "    \n",
    "    def setup_U(self):\n",
    "        U = Sequential()\n",
    "        for i in range(self.l_count):\n",
    "            U.add(Dense(data.shape[0], activation='relu'))\n",
    "        u_embedding = Embedding(users, features, input_length=1)\n",
    "        U.add(u_embedding)\n",
    "        U.add(Reshape((features,)))\n",
    "        return U\n",
    "    \n",
    "    def predict_rating(self, user, item):\n",
    "        return self.predict([np.array([user]), np.array([item])])[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no general rule as to which of vanilla matrix factorization or deep matrix factorization will perfectly fit a problem. Most times, it doesn't hurt to try out both and compare performance. The most compromising issues with the vanilla implementation is inclusion on non-linear interactions in the matrix while for deep matrix factorization, it can be either negative sampling ratio, depth of network(too deep? overfits . too shallow? underfits) and the factors of the final hidden state. As a general form of reference, [Li et al., 2015; Sedhain et al., 2015; Strub and Mary, 2015] all have performance benchmarks for the implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for reading.\n",
    "\n",
    "*This post was written entirely in the IPython notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "1. [https://www.yuspify.com/blog/cold-start-problem-recommender-systems/](https://www.yuspify.com/blog/cold-start-problem-recommender-systems/)\n",
    "2. [https://dspace.mit.edu/handle/1721.1/99785](https://dspace.mit.edu/handle/1721.1/99785)\n",
    "3. [https://sifter.org/simon/journal/20061211.html](https://sifter.org/simon/journal/20061211.html)\n",
    "4. [https://www.netflixprize.com/](https://www.netflixprize.com/)\n",
    "1. [https://arxiv.org/pdf/1809.02131.pdf](https://arxiv.org/pdf/1809.02131.pdf)\n",
    "2. [https://github.com/maciejkula/triplet_recommendations_keras](https://github.com/maciejkula/triplet_recommendations_keras)\n",
    "3. [https://github.com/bradleypallen/keras-movielens-cf](https://github.com/bradleypallen/keras-movielens-cf)\n",
    "4. [https://colab.research.google.com/github/jmschrei/notebooks](https://colab.research.google.com/github/jmschrei/notebooks/blob/master/MXNet%20Deep%20Matrix%20Factorization/MxNet_Deep_Matrix_Factorization.ipynb#scrollTo=KgozQGuYAZP0)\n",
    "5. [http://blog.richardweiss.org/2016/09/25/movie-embeddings.html](http://blog.richardweiss.org/2016/09/25/movie-embeddings.html)\n",
    "6. [https://www.ijcai.org/proceedings/2017/0447.pdf](https://www.ijcai.org/proceedings/2017/0447.pdf)\n",
    "7. [https://github.com/khanhnamle1994/movielens/blob/master/CFModel.py](https://github.com/khanhnamle1994/movielens/blob/master/CFModel.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
